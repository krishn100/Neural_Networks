


# Imports
import pandas as pd
from pathlib import Path
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler,OneHotEncoder








# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame
applicant_data_df = pd.read_csv(
    Path("applicants_data.csv")
)# YOUR CODE HERE

# Review the DataFrame
# YOUR CODE HERE
applicant_data_df.head()


# Review the data types associated with the columns
# YOUR CODE HERE
applicant_data_df.info()





# Drop the 'EIN' and 'NAME' columns from the DataFrame
applicant_data_df = applicant_data_df.drop(['EIN', 'NAME'], axis=1)

# Review the DataFrame
# YOUR CODE HERE
applicant_data_df.head()





# Create a list of categorical variables 
categorical_variables = ["APPLICATION_TYPE", "AFFILIATION", "CLASSIFICATION", "USE_CASE", 

# Display the categorical variables list
# YOUR CODE HERE



# Create a OneHotEncoder instance
enc = # YOUR CODE HERE



# Encode the categorcal variables using OneHotEncoder
encoded_data = # YOUR CODE HERE



# Create a DataFrame with the encoded variables
encoded_df = # YOUR CODE HERE

# Review the DataFrame
# YOUR CODE HERE






# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame
encoded_df = # YOUR CODE HERE

# Review the Dataframe
# YOUR CODE HERE






# Define the target set y using the IS_SUCCESSFUL column
y = # YOUR CODE HERE

# Display a sample of y
# YOUR CODE HERE



# Define features set X by selecting all columns but IS_SUCCESSFUL
X = # YOUR CODE HERE

# Review the features DataFrame
# YOUR CODE HERE






# Split the preprocessed data into a training and testing dataset
# Assign the function a random_state equal to 1
X_train, X_test, y_train, y_test = # YOUR CODE HERE






# Create a StandardScaler instance
scaler = # YOUR CODE HERE

# Fit the scaler to the features training dataset
X_scaler = # YOUR CODE HERE

# Fit the scaler to the features training dataset
X_train_scaled = # YOUR CODE HERE
X_test_scaled = # YOUR CODE HERE









# Define the the number of inputs (features) to the model
number_input_features = # YOUR CODE HERE

# Review the number of features
number_input_features



# Define the number of neurons in the output layer
number_output_neurons = # YOUR CODE HERE


# Define the number of hidden nodes for the first hidden layer
hidden_nodes_layer1 =  # YOUR CODE HERE

# Review the number hidden nodes in the first layer
hidden_nodes_layer1



# Define the number of hidden nodes for the second hidden layer
hidden_nodes_layer2 =  # YOUR CODE HERE

# Review the number hidden nodes in the second layer
hidden_nodes_layer2



# Create the Sequential model instance
nn = # YOUR CODE HERE



# Add the first hidden layer
# YOUR CODE HERE



# Add the second hidden layer
# YOUR CODE HERE



# Add the output layer to the model specifying the number of output neurons and activation function
# YOUR CODE HERE



# Display the Sequential model summary
# YOUR CODE HERE






# Compile the Sequential model
# YOUR CODE HERE



# Fit the model using 50 epochs and the training data
# YOUR CODE HERE






# Evaluate the model loss and accuracy metrics using the evaluate method and the test data
model_loss, model_accuracy = # YOUR CODE HERE

# Display the model loss and accuracy results
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")





# Set the model's file path
file_path = # YOUR CODE HERE

# Export your model to a HDF5 file
# YOUR CODE HERE












# Define the the number of inputs (features) to the model
number_input_features = len(X_train.iloc[0])

# Review the number of features
number_input_features


# Define the number of neurons in the output layer
number_output_neurons_A1 = # YOUR CODE HERE


# Define the number of hidden nodes for the first hidden layer
hidden_nodes_layer1_A1 = # YOUR CODE HERE

# Review the number of hidden nodes in the first layer
hidden_nodes_layer1_A1


# Create the Sequential model instance
nn_A1 = # YOUR CODE HERE


# First hidden layer
# YOUR CODE HERE


# Output layer
# YOUR CODE HERE


# Check the structure of the model
# YOUR CODE HERE


# Compile the Sequential model
nn_A1.# YOUR CODE HERE



# Fit the model using 50 epochs and the training data
fit_model_A1 = # YOUR CODE HERE






# Define the the number of inputs (features) to the model
number_input_features = len(X_train.iloc[0])

# Review the number of features
number_input_features


# Define the number of neurons in the output layer
number_output_neurons_A2 = # YOUR CODE HERE


# Define the number of hidden nodes for the first hidden layer
hidden_nodes_layer1_A2 = # YOUR CODE HERE

# Review the number of hidden nodes in the first layer
hidden_nodes_layer1_A2


# Create the Sequential model instance
nn_A2 = # YOUR CODE HERE


# First hidden layer
# YOUR CODE HERE

# Output layer
# YOUR CODE HERE

# Check the structure of the model
# YOUR CODE HERE



# Compile the model
# YOUR CODE HERE



# Fit the model
# YOUR CODE HERE






print("Original Model Results")

# Evaluate the model loss and accuracy metrics using the evaluate method and the test data
model_loss, model_accuracy = # YOUR CODE HERE

# Display the model loss and accuracy results
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")


print("Alternative Model 1 Results")

# Evaluate the model loss and accuracy metrics using the evaluate method and the test data
model_loss, model_accuracy =# YOUR CODE HERE

# Display the model loss and accuracy results
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")


print("Alternative Model 2 Results")

# Evaluate the model loss and accuracy metrics using the evaluate method and the test data
model_loss, model_accuracy = # YOUR CODE HERE

# Display the model loss and accuracy results
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")





# Set the file path for the first alternative model
file_path = # YOUR CODE HERE

# Export your model to a HDF5 file
# YOUR CODE HERE



# Set the file path for the second alternative model
file_path = # YOUR CODE HERE

# Export your model to a HDF5 file
# YOUR CODE HERE




